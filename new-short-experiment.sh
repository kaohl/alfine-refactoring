#!/usr/bin/env bash

# This script should be executed in the Alfine home folder.

# Uncomment these to generate all data in one go.
# declare -a projects=("extendj-bms" "jacop-bms")
# declare -a types=("extract-method" "inline-method" "inline-constant" "extract-constant" "rename")

# Replace these with above expressions to generate all data.
declare -a projects=("extendj-bms" "jacop-bms")
declare -a types=("extract-method" "inline-method")

# Alfine export-command argument. (Specify all variable projects.)

variableProjects="extendj-8.1.2 jacop-4.6.0"

# Assume `baseDir` exists and contains our refactoring
# framework (eclipse rcp-application).

baseDir=experiment
workspacesDir=$baseDir/workspaces
dataRootDir=$baseDir/data

# Path to framework application relative `$baseDir` directory.
framework="eclipse2/eclipse"

# Name of cache dir in workspace. 
cacheDirName=oppcache

# rm    -rf $dataRootDir
mkdir -p  $dataRootDir

for project in "${projects[@]}"; do

    # Export benchmark-project assets.

    preparedWorkspaceDir=$workspacesDir/$project/workspace
    preparedWorkspaceAssetsDir=$preparedWorkspaceDir/assets
    preparedWorkspaceOutputDir=$preparedWorkspaceDir/output

    projectSrcDir=$preparedWorkspaceAssetsDir/src
    projectLibDir=$preparedWorkspaceAssetsDir/lib

    if [ -d $preparedWorkspaceDir ]; then
        continue; # Workspace already prepared.
    fi

    # Prepare a workspace for the project (set up eclipse
    # projects and cache refactoring opportunities).

    mkdir -p $projectSrcDir
    mkdir -p $projectLibDir

    # Set up assets directory in workspace.

    java -jar alfine.jar\
         --command  export\
         --project  $project\
         --src      $projectSrcDir\
         --lib      $projectLibDir\
         --variable $variableProjects

    # Set up empty output directory.
    mkdir $preparedWorkspaceDir/output

    # Set up eclipse projects and cache refactoring opportunities.
    ./experiment/$framework\
        -data      $preparedWorkspaceDir\
        --prepare\
        --src      assets/src\
        --lib      assets/lib\
        --cache    $cacheDirName\
        --out      output\
        --type     rename
    # The specified type above is a dummy argument because the `type` option is required...
done

function refactor {

    procID=$1; project=$2; type=$3; n=$4

    args="--limit 1000 --type $type"
    typeargs=""

    case $type in
        "rename")
            typeargs="--length 49"
        ;;
        *)
	    # No additional type specific arguments.
        ;;
    esac

    args="$args $typeargs"

    # Refactor assets.

    preparedWorkspaceDir=$workspacesDir/$project/workspace

    dataDir=$dataRootDir/$project/$type/"d$n"

    procDir=$baseDir/process-$procID
    procWorkspaceDir=$procDir/workspace
    procOutputDir=$procWorkspaceDir/output

    # Replace proc workspace with a fresh copy.

    rm -rf $procWorkspaceDir
    cp -r $preparedWorkspaceDir $procDir

    # Note
    #  `seed`, `shuffle`, and `select` are seeds for pseudorandom number
    #  generators. They are used for generating identifiers (rename-refactorings
    #  only), for sorting opportunities (always), and for selecting interval
    #  length in extract method refactorings, respectively. All seeds default to
    #  zero unless specified.

    # Construct command (will be executed from workspace directory!)

    seeds="--seed $((RANDOM)) --shuffle $((RANDOM)) --select $((RANDOM))"
    cmd="../../$framework -data . --cache $cacheDirName --src assets/src --lib assets/lib --out output $seeds $args"

    # Execute command.

    cd $procWorkspaceDir

    eval $cmd > output.log

    cd -

    # Check status (abort on failure).

    # We assume that the refactoring framework only output new
    # archives if a refactoring was successfully applied.

    if [ ! "$(ls -A $procOutputDir)" ]; then
        echo "Failed to refactor project (with n=$n): No output was generated by refactoring."
	return;
    fi

    # Save command and output.
    
    mkdir -p $dataDir

    echo "$cmd" > $dataDir/cmd.txt

    # Always save `output.log` (can be quite large in size).
    # However, let the user choose whether to discard it.

    cp $procOutputDir/output.log \
       $dataDir

    # Generate patch files.

    # The `ls` command will print an error for each
    # brace-expanded pattern that fails to match any
    # files. However, we still get a list of all
    # successfully matched files by other patterns.

    archives=$(ls $preparedWorkspaceDir/assets/src/*.{jar,zip})

    # Save new versions of archives for debugging purposes.

    outputJarsDir=$dataDir/jars

    mkdir $outputJarsDir
    
    for old in $archives
    do
        filename=$(basename $old)
        new=$procOutputDir/$filename
        out=$dataDir/$filename.patch

        if [[ -e $new ]]; then
            $ALFINE_HOME/lib/jdiff.sh $old $new $out
        else
	    # Should we use `touch` instead?
            echo "" > $out
        fi

	# Save new version of archive.
	# cp $new $outputJarsDir/$filename
    done
    
}

# Start one refactoring process per processing unit.

n=`nproc`            # Number of available processing units.
total=$n             # Number of refactorings per project per type.
m=$(( $total / $n )) # Number of refactorings per process.
n_times_m=$(( $n * $m )) # Actual number of refactorings per project per type.

if [[ ! $n_times_m == $total ]]; then
    echo "Total number of refactorings per type ($total) is not evenly"\
         "divisible by the number of available processing units ($n)."\
         "$n_times_m refactorings will be created."
fi

for project in "${projects[@]}"
do
    # This loop divides the work evenly on all available processing units.
    # Because all refactorings of the same project and type takes approximately
    # the same time, all batches in the inner-most loop terminates approximately
    # at the same time.
    #
    # The call to `wait` will make the main process wait for all processes created
    # in the inner loop before running refactorings of the next (project, type)-pair.

    for type in "${types[@]}"; do

        # Create data output directory for project and type.
        mkdir -p $dataRootDir/$project/$type

        for i in $(seq $n); do
            (
                echo "starting project = $project, type = $type, batch = $i"

                procID=$i

		# Refresh process directory.

		procDir=$baseDir/process-$procID

		rm    -rf $procDir
                mkdir -p  $procDir

		# Run $m refactorings in this process and then sync.

                for j in $(seq $m); do
                    refactor $procID $project $type $(( "$m * ( $i - 1 ) + $j" ))
                done
            ) &
        done
        time wait # Wait for (inner loop) all known process IDs.
    done
done
